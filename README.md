### Дипломный проект. Кредитный скоринг
#### Цель проекта:
Предсказать возврат кредита клиентом с просрочкой не более 90 дней.

#### Задачи: 
Построить эффективную скоринговую модель, которая бы предсказывала наступление дефолта клиента. Для этого используем различные алгоритмы классификации: логистическую регрессию, XGBoost и CatBoost, посмотрим, какая из них покажет лучший результат.

#### О данных

Предоставлена информация из анкетных данных заемщиков, данных об итогах уже выданных кредитов и факт наступления дефолта.

#### Этапы работы
-Анализ исходных данных (проверка на дубликаты и выбросы); 

-Корреляционный анализ с целью выявить, какие признаки оставить для постороения модели;

-Генерация новых признаков;

-Построим "наивную"/baseline модель, предсказывающую наступление дефолта по полу и возрасту заемщика (с ней будем сравнивать другие модели)

-Обработаем и отнормируем признаки;

-Сделаем первую модель на основе логистической регрессии, возьмем все данные, которые у нас есть;

-Сделаем вторую модель на основе градиентного бустинга с помощью XGBoost;

-Сделаем третью модель на основе градиентного бустинга с помощью CatBoost;

-Удалим сильно скоррелированные признаки;

-Сделаем четвертую модель на основе градиентного бустинга с помощью XGBoost и подобранных признаков;

-Подберем параметры для XGBoost и сравним результаты;

-Сделаем шестую модель на основе градиентного бустинга с помощью CatBoost и подобранных признаков;

-Улучшим результаты модели CatBoost при помощи кроссвалидации.


#### Подготовка данных
Предоставленные данные довольно чистые. В нескольких признаках были найдены и заполнены пропуски. 
В процессе подготовки было добавлено несколько новых признаков.
Была выполнена нормализация числовых признаков при помощи MinMaxScaler, также обработка One-Hot Encoding категориальныз переменных.


#### Построение моделей
1. Логистическая регрессия

Модель показала достаточно хороший результат, критерий Gini 43%, значит она достаточно хорошо разделяет тех, кто вернет кредит и кто нет. Логистическую регрессию использую многие банки, т.к. им важна легкая интерпретируемость модели.

2. MODEL 2. XGBoost

Модель XGBoost показала лучший результат по accuracy, точности, ROC_AUC и Gini, но у нее немного ниже полнота и F1-мера. Она лучше разделяет дефолты и не дефолты. У нее больше ошибка 1 рода, но меньше ошибка 2 рода по сравнению с логистической регрессией.

3. MODEL 3. CATBOOST

CatBoost на параметрах по умолчанию показала результат хуже, чем логистическая регрессия. У нее неплохой коэффициент Gini, но достаточно большая по сравнению с другими моделями ошибка второго рода. Это плохо, т.к. может привести к упущенной прибыли финансовой организации.

4. Подбор признаков и гиперпараметров для модели XGBoost:

Подбор параметров позволил улучшить полноту, F1 меру и коэффициент Gini, но незначительно снизил точность. Наша модель с подбором параметров лучше всего выявляет факт дефолта и имеет самый высокий критейрий Gini, т.е. лучше всего разделяет классы.

5. Модель CatBoost с подбором признаков:

Подбор признаков значительно улучшил качество модели CatBoost. F1-score вырос с 38,21% до 44,14%, коэффициент Gini также улучшился с 44.67% до 45.53%. Попробуем добавить к модели CatBoost кроссвалидацию

6. CatBoost + CV

Благодаря подбору признаков и применению кроссвалидции критерий Gini удалось увеличить с 44.66% до 56.46% - значит, она лучше всего разделяет "положительный" и "отрицательный" классы.

### Итоги и выводы
При работе над проектом была проведена большая комплексная работа. Были применены следующие навыки:

-Иследование, обработка и подготовка данных, генерация новых признаков. Закреплены знания о библиотеках pandas, numpy, matplotlib, seaborn, scipy

-Построение ML моделей. Закреплены знания о моделях LinearRegression, CatBoost, изучена модель градиентного бустинга XGBoost

Из результатов работы можно сделать вывод, что данная задача хорошо решается с помощью машинного обучения, градиентные бустинги отработали заведомо лучше, чем модель логистичесой регрессии.

1. Мы попробовали 3 модели для кредитного скоринга, лучше всего на наших данных себя показала модель XGBoost, поэтому для нее был сделан дополнительный отбор признаков и подбор оптимальных параметров. Также после подбора признаков мы построили модель CatBoost  и сделали на ней кроссвалидацию - этот вариант показал самый лучший результат.
2. После подбора признаков и параметров, модель XGBoost показала критерий Gini  порядка 47%, это говорит о достаточно успешном разделении тех, кто вернет кредит и тех, у кого может случиться дефолт.
3. Благодаря подбору признаков и параметров XGBoost удалось увеличить F1 меру с 42.25% до 46.79%, это говорит о повышении уверенности разделения моделью двух классов к «положительным» и «отрицательным», что особенно релевантно для задачи кредитного скоринга.
4. Самый лучший результат на наших данных показала модель CatBoost  с использованием кроссвалидации. Благодаря подбору признаков и применению кроссвалидции  критерий Gini удалось увеличить с 44.66% до 56.46% - значит, она лучше всего разделяет "положительный" и "отрицательный" классы.